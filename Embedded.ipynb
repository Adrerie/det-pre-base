{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3256be9",
   "metadata": {},
   "source": [
    "此处用于聚合所有模块进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_experiment_runner_v2.py\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from dbl_loss_tsd import DBLDetectionTrainer # 确保dbl_loss_tsd.py和这个脚本在同一目录\n",
    "\n",
    "def run_experiment(model_yaml: str, experiment_name: str, use_dbl_loss: bool):\n",
    "    \"\"\"\n",
    "    A standardized function to run a full experiment, now with adaptive training strategies.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*25} STARTING EXPERIMENT: {experiment_name} {'='*25}\")\n",
    "    \n",
    "    # === Step 1: Build model and transfer weights ===\n",
    "    print(f\"--- Building model from '{model_yaml}' and loading 'yolo11n.pt' weights ---\")\n",
    "    # For experiments with new modules, this loads pretrained weights into the matching backbone parts.\n",
    "    model = YOLO(model_yaml).load(\"yolo11n.pt\")\n",
    "    \n",
    "    # === Step 2: Setup Trainer and Callbacks ===\n",
    "    trainer_class = DBLDetectionTrainer if use_dbl_loss else None\n",
    "    setup_tensorboard(experiment_name)\n",
    "    try:\n",
    "        model.add_callback(\"on_fit_epoch_end\", tb_on_fit_epoch_end)\n",
    "        model.add_callback(\"on_train_end\", tb_on_train_end)\n",
    "    except NameError:\n",
    "        print(\"TensorBoard callbacks not found.\")\n",
    "    _device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # <<< MODIFICATION: Adaptive Training Strategy Selection >>>\n",
    "    if use_dbl_loss:\n",
    "        # --- STRATEGY B: Global Adaptive Fine-tuning (for DBL Loss) ---\n",
    "        print(\"\\n--- Applying STRATEGY B: Global Adaptive Fine-tuning ---\")\n",
    "        print(\"Reason: DBL_TSD loss is a fundamental change. All layers will train together.\")\n",
    "        \n",
    "        model.train(\n",
    "            trainer=trainer_class,\n",
    "            data=\"pest24.yaml\",\n",
    "            seed=42,\n",
    "            epochs=80, # Can use a slightly shorter total epoch count for this aggressive strategy\n",
    "            batch=24,\n",
    "            workers=2,\n",
    "            lr0=5e-5,      # A moderate initial learning rate\n",
    "            lrf=1e-6,\n",
    "            optimizer=\"AdamW\",\n",
    "            weight_decay=0.001,\n",
    "            patience=20,\n",
    "            name=f\"{experiment_name}_global_adapt\",\n",
    "            device=_device,\n",
    "            cache=True,\n",
    "            amp=True\n",
    "        )\n",
    "    else:\n",
    "        # --- STRATEGY A: Two-Stage Fine-tuning (for Architectural Changes) ---\n",
    "        print(\"\\n--- Applying STRATEGY A: Two-Stage Fine-tuning ---\")\n",
    "        print(\"Reason: New architectural modules need to be warmed up.\")\n",
    "\n",
    "        # STAGE 1: Warmup New/Modified Modules\n",
    "        print(\"\\n--- STAGE 1: WARMUP - Training only the Head/Neck ---\")\n",
    "        for i in range(11): # Freeze backbone\n",
    "            if i < len(model.model.model):\n",
    "                for param in model.model.model[i].parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        model.train(\n",
    "            trainer=trainer_class, data=\"pest24.yaml\", epochs=30, lr0=1e-4, \n",
    "            batch=24, workers=2, device=_device, name=f\"{experiment_name}_stage1_warmup\"\n",
    "        )\n",
    "\n",
    "        # STAGE 2: Global Fine-tuning\n",
    "        print(\"\\n--- STAGE 2: FINETUNE - Training all layers ---\")\n",
    "        for param in model.model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        model.train(\n",
    "            trainer=trainer_class, data=\"pest24.yaml\", epochs=70, lr0=5e-6, lrf=1e-6,\n",
    "            batch=24, workers=2, device=_device, name=f\"{experiment_name}_stage2_global\",\n",
    "            seed=42, optimizer=\"AdamW\", weight_decay=0.001, patience=20\n",
    "        )\n",
    "\n",
    "    # === Final Step: Save final model ===\n",
    "    final_weights_path = f\"weights/{experiment_name}_final.pt\"\n",
    "    model.save(final_weights_path)\n",
    "    print(f\"\\n{'='*25} EXPERIMENT {experiment_name} COMPLETE {'='*25}\")\n",
    "    print(f\"Final model saved to {final_weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 单独验证 ---\n",
    "# 实验1: 仅Fusion Neck (架构改动 -> 策略A)\n",
    "run_experiment(\"yamls/yolo11n-fusion.yaml\", \"exp_fusion_only\", use_dbl_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b072ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验2: ECA + Fusion (架构改动 -> 策略A)\n",
    "run_experiment(\"yamls/yolo11n-eca-fusion.yaml\", \"exp_eca_fusion\", use_dbl_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验3: CSAB + Fusion (架构改动 -> 策略A)\n",
    "run_experiment(\"yamls/yolo11n-csab-fusion.yaml\", \"exp_csab_fusion\", use_dbl_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c83420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验4: DBL + Fusion (架构+损失改动 -> 策略B)\n",
    "# The loss change is more fundamental, so we choose the global strategy.\n",
    "run_experiment(\"yamls/yolo11n-fusion.yaml\", \"exp_dbl_fusion\", use_dbl_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f63b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# 实验5: ECA + CSAB + Fusion (架构改动 -> 策略A)\n",
    "run_experiment(\"yamls/yolo11n-ultimate.yaml\", \"exp_ultimate_no_dbl\", use_dbl_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75004ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验6: ECA + CSAB + Fusion + DBL (架构+损失改动 -> 策略B)\n",
    "# Again, the fundamental loss change dictates the strategy.\n",
    "run_experiment(\"yamls/yolo11n-ultimate.yaml\", \"exp_ultimate_with_dbl\", use_dbl_loss=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
